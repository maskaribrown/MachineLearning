{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-data-analysis/resources/0dhYG) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Hypothesis Testing\n",
    "This assignment requires more individual learning than previous assignments - you are encouraged to check out the [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/) to find functions or methods you might not have used yet, or ask questions on [Stack Overflow](http://stackoverflow.com/) and tag them as pandas and python related. And of course, the discussion forums are open for interaction with your peers and the course staff.\n",
    "\n",
    "Definitions:\n",
    "* A _quarter_ is a specific three month period, Q1 is January through March, Q2 is April through June, Q3 is July through September, Q4 is October through December.\n",
    "* A _recession_ is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
    "* A _recession bottom_ is the quarter within a recession which had the lowest GDP.\n",
    "* A _university town_ is a city which has a high percentage of university students compared to the total population of the city.\n",
    "\n",
    "**Hypothesis**: University towns have their mean housing prices less effected by recessions. Run a t-test to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom. (`price_ratio=quarter_before_recession/recession_bottom`)\n",
    "\n",
    "The following data files are available for this assignment:\n",
    "* From the [Zillow research data site](http://www.zillow.com/research/data/) there is housing data for the United States. In particular the datafile for [all homes at a city level](http://files.zillowstatic.com/research/public/City/City_Zhvi_AllHomes.csv), ```City_Zhvi_AllHomes.csv```, has median home sale prices at a fine grained level.\n",
    "* From the Wikipedia page on college towns is a list of [university towns in the United States](https://en.wikipedia.org/wiki/List_of_college_towns#College_towns_in_the_United_States) which has been copy and pasted into the file ```university_towns.txt```.\n",
    "* From Bureau of Economic Analysis, US Department of Commerce, the [GDP over time](http://www.bea.gov/national/index.htm#gdp) of the United States in current dollars (use the chained value in 2009 dollars), in quarterly intervals, in the file ```gdplev.xls```. For this assignment, only look at GDP data from the first quarter of 2000 onward.\n",
    "\n",
    "Each function in this assignment below is worth 10%, with the exception of ```run_ttest()```, which is worth 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dictionary to map state names to two letter acronyms\n",
    "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "umich_part_id": "021",
    "umich_partlist_id": "004"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Auburn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Florence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Jacksonville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Livingston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montevallo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>RiverFalls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>StevensPoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Waukesha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Whitewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Laramie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         State    RegionName\n",
       "0      Alabama        Auburn\n",
       "1      Alabama      Florence\n",
       "2      Alabama  Jacksonville\n",
       "3      Alabama    Livingston\n",
       "4      Alabama    Montevallo\n",
       "..         ...           ...\n",
       "519  Wisconsin    RiverFalls\n",
       "520  Wisconsin  StevensPoint\n",
       "521  Wisconsin      Waukesha\n",
       "522  Wisconsin    Whitewater\n",
       "523    Wyoming       Laramie\n",
       "\n",
       "[524 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_list_of_university_towns():\n",
    "    '''Returns a DataFrame of towns and the states they are in from the \n",
    "    university_towns.txt list. The format of the DataFrame should be:\n",
    "    DataFrame( [ [\"Michigan\", \"Ann Arbor\"], [\"Michigan\", \"Yipsilanti\"] ], \n",
    "    columns=[\"State\", \"RegionName\"]  )\n",
    "    \n",
    "    The following cleaning needs to be done:\n",
    "\n",
    "    1. For \"State\", removing characters from \"[\" to the end.\n",
    "    2. For \"RegionName\", when applicable, removing every character from \" (\" to the end.\n",
    "    3. Depending on how you read the data, you may need to remove newline character '\\n'. '''\n",
    "    \n",
    "#     from io import StringIO\n",
    "#     uni_towns = pd.read_csv(StringIO(data))\n",
    "#     uni_towns = pd.read_csv(\n",
    "#         'university_towns.txt',\n",
    "#         header='1'\n",
    "#         header=[0,10]\n",
    "#         delim_whitespace=True,\n",
    "#         colspecs=[(0,5), (5, 2000)]\n",
    "#         delimiter=' '\n",
    "#     )\n",
    "#     uni_towns = pd.read_csv('university_towns.txt', delimiter= '\\s+', index_col=False)\n",
    "#     uni_towns = pd.read_fwf(\n",
    "#         'university_towns.txt',\n",
    "# #         header='1'\n",
    "# #         header=[0,10]\n",
    "# #         delim_whitespace=True,\n",
    "# #         colspecs=[(0,5), (5, 2000)]\n",
    "# #         delimiter=' '\n",
    "#     )\n",
    "\n",
    "#     uni_towns = pd.read_csv(\n",
    "#         'university_towns.txt',\n",
    "#         delimiter = \"\\t\",\n",
    "#         chunksize=1,\n",
    "#     )\n",
    "    \n",
    "    df = pd.read_table('university_towns.txt',header = None)\n",
    "#     result = []\n",
    "    d = {'State': [], 'RegionName': []}\n",
    "    res = pd.DataFrame(data=d)\n",
    "    \n",
    "    states_set = set(states.values())\n",
    "#     print(states_set)\n",
    "#     state = str(df.iloc[0].values)[2:-8]\n",
    "    state = ''\n",
    "    for i in range(0,len(df)):\n",
    "        try:\n",
    "            val = df.iloc[i]\n",
    "            val = val.str.replace('\\[(.*?)\\]', '')\n",
    "            val = val.str.replace('\\(.*', ' ')\n",
    "            val = val.str.replace('\\s+', '')[0]\n",
    "\n",
    "            if val in states_set:\n",
    "                state = val\n",
    "            else:\n",
    "#                 print(res.DataFrame([state, val], columns=['State', 'RegionName']))\n",
    "                res = res.append({'State': state, 'RegionName': val}, ignore_index=True)\n",
    "#                 res.concat(\n",
    "#                     [res.DataFrame([state, val], columns=['State', 'RegionName'])],\n",
    "#                       ignore_index=True\n",
    "#                 )\n",
    "#                 res = res.append([state, val], ignore_index=True)\n",
    "#             print(val.values)\n",
    "#             if val.str.contains('\\('):\n",
    "#                 # not a state\n",
    "#                 print('jere', val.str)\n",
    "# #             else:\n",
    "#                 #state\n",
    "#                 state = val.str\n",
    "#                 print('state:{}'.format(state))\n",
    "#             print(val.str.contains('\\('))\n",
    "# #             if val.str.contains('('):\n",
    "# #                 print(val)\n",
    "        except Exception:\n",
    "            pass\n",
    "#             print(val.str.contains('[').bool())\n",
    "#         if val.contains('[edit]'):\n",
    "#             print(val)\n",
    "#         val = df.iloc[i].values[0]\n",
    "#         if val.\n",
    "#         startswith\n",
    "#         print(df.iloc[i].values[0])\n",
    "\n",
    "#     uni_towns.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n",
    "#     print(uni_towns.iloc[6])\n",
    "#     for p in uni_towns:\n",
    "#         print(p.iloc[0])\n",
    "\n",
    "#     res = res.set_index(['State','RegionName'])\n",
    "    return res\n",
    "\n",
    "get_list_of_university_towns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "umich_part_id": "022",
    "umich_partlist_id": "004"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2008q3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recession_start():\n",
    "    '''Returns the year and quarter of the recession start time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    \n",
    "    GDP = pd.read_excel(\n",
    "        'gdplev.xls',\n",
    "        usecols=[4,5],\n",
    "        header=[5],\n",
    "        skiprows=2,\n",
    "        index_col=0\n",
    "    )\n",
    "\n",
    "    GDP = GDP.loc['2000q1':,:]\n",
    "    GDP.rename(columns={'Unnamed: 5': 'q_gdp'}, inplace=True)\n",
    "    GDP['tmp'] = (GDP['q_gdp'] < GDP['q_gdp'].shift(-1))\n",
    "    GDP['tmp2'] = (GDP['tmp'] == False) & (GDP['tmp'].shift(-1) == False)\n",
    "    \n",
    "    return GDP.iloc[np.where(GDP['tmp2'] == True)].iloc[0].name\n",
    "#     GDP.reset_index()\n",
    "\n",
    "#     print(GDP.head(40))\n",
    "#     GDP['tmp'] = np.where(\n",
    "#         [GDP['q_gdp'] < GDP['q_gdp'].shift(-1)]\n",
    "#     )\n",
    "#     print(GDP)\n",
    "#     print(GDP)\n",
    "#     GDP.rename(columns={'GDP in billions of current dollars.1': 'gdp'}, inplace=True)\n",
    "#     GDP = GDP.set_index('year_quarter')\n",
    "#     GDP['growth_direction'] = True if (GDP.gdp.eq(GDP.gdp.shift()) >= 0) else False\n",
    "\n",
    "\n",
    "#     GDP['Position1'] = np.where(\n",
    "#         (\n",
    "#             GDP['gdp'] < GDP['gdp'].shift(-1)\n",
    "#         )\n",
    "#         ,\n",
    "#         True,\n",
    "#         False\n",
    "#     )\n",
    "\n",
    "\n",
    "#     GDP['Position2'] = np.where(\n",
    "#         (\n",
    "#             (GDP['gdp'].shift(-1) < GDP['gdp'].shift(-2))\n",
    "#         )\n",
    "#         ,\n",
    "#         True,\n",
    "#         False\n",
    "#     )\n",
    "\n",
    "#     x = (GDP['gdp'] < GDP['gdp'].shift(-1))\n",
    "#     x = x['2006q1':]\n",
    "#     mask = (GDP['gdp'].shift(-1) >= GDP['gdp'].shift(-2))['2006q1':]\n",
    "#     mask = mask.where(mask == False, inplace=True)\n",
    "    \n",
    "#     x.rename(columns={'year_quarter', 'asdas'}, inplace=True)\n",
    "\n",
    "#     filtered = np.where(\n",
    "#         [GDP['Position1'] == False & GDP['Position2'] == False]\n",
    "#     )\n",
    "    \n",
    "#     return GDP.iloc[filtered[1][0]].name\n",
    "#     print(GDP[GDP['Position1'] == False & GDP['Position2'] == False])\n",
    "\n",
    "#     print(GDP)\n",
    "#     ngative_growth_quarters = np.where(GDP['Position'] == True)\n",
    "#     return GDP.iloc[ngative_growth_quarters[0][0]].name\n",
    "\n",
    "get_recession_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "umich_part_id": "023",
    "umich_partlist_id": "004"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009q4'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recession_end():\n",
    "    '''Returns the year and quarter of the recession end time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    \n",
    "    recession_start = get_recession_start()\n",
    "\n",
    "    GDP = pd.read_excel(\n",
    "        'gdplev.xls',\n",
    "        usecols=[4,5],\n",
    "        header=[5],\n",
    "        skiprows=2,\n",
    "        index_col=0\n",
    "    )\n",
    "\n",
    "    GDP = GDP.loc[recession_start:,:]\n",
    "    GDP.rename(columns={'Unnamed: 5': 'q_gdp'}, inplace=True)\n",
    "#     print(GDP)\n",
    "    GDP['tmp'] = (GDP['q_gdp'] > GDP['q_gdp'].shift(-1))\n",
    "#     GDP['tmp2'] = (GDP['tmp'] == False) & (GDP['tmp'].shift(-1) == False)\n",
    "    return GDP.iloc[np.where(GDP['tmp'] == False)].iloc[2:,:].iloc[0].name\n",
    "\n",
    "get_recession_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "umich_part_id": "024",
    "umich_partlist_id": "004"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009q2'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recession_bottom():\n",
    "    '''Returns the year and quarter of the recession bottom time as a \n",
    "    string value in a format such as 2005q3\n",
    "    A recession bottom is the quarter within a recession which had the lowest GDP.'''\n",
    "    \n",
    "    recession_start = get_recession_start()\n",
    "    recession_end = get_recession_end()\n",
    "\n",
    "    GDP = pd.read_excel(\n",
    "        'gdplev.xls',\n",
    "        usecols=[4,5],\n",
    "        header=[5],\n",
    "        skiprows=2,\n",
    "        index_col=0\n",
    "    )\n",
    "\n",
    "    GDP = GDP.loc[recession_start:recession_end,:]\n",
    "    GDP.rename(columns={'Unnamed: 5': 'q_gdp'}, inplace=True)\n",
    "    return GDP.idxmin()['q_gdp']\n",
    "\n",
    "get_recession_bottom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "umich_part_id": "025",
    "umich_partlist_id": "004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>2000q1</th>\n",
       "      <th>2000q2</th>\n",
       "      <th>2000q3</th>\n",
       "      <th>2000q4</th>\n",
       "      <th>2001q1</th>\n",
       "      <th>2001q2</th>\n",
       "      <th>2001q3</th>\n",
       "      <th>2001q4</th>\n",
       "      <th>2002q1</th>\n",
       "      <th>2002q2</th>\n",
       "      <th>...</th>\n",
       "      <th>2014q2</th>\n",
       "      <th>2014q3</th>\n",
       "      <th>2014q4</th>\n",
       "      <th>2015q1</th>\n",
       "      <th>2015q2</th>\n",
       "      <th>2015q3</th>\n",
       "      <th>2015q4</th>\n",
       "      <th>2016q1</th>\n",
       "      <th>2016q2</th>\n",
       "      <th>2016q3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Abbeville</th>\n",
       "      <th>Alabama</th>\n",
       "      <td>46354.666667</td>\n",
       "      <td>47571.666667</td>\n",
       "      <td>48219.000000</td>\n",
       "      <td>47987.000000</td>\n",
       "      <td>48830.000000</td>\n",
       "      <td>49521.000000</td>\n",
       "      <td>49568.666667</td>\n",
       "      <td>50117.000000</td>\n",
       "      <td>50744.666667</td>\n",
       "      <td>51956.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>74878.333333</td>\n",
       "      <td>75553.666667</td>\n",
       "      <td>76087.666667</td>\n",
       "      <td>76631.000000</td>\n",
       "      <td>77208.000000</td>\n",
       "      <td>77741.666667</td>\n",
       "      <td>78313.333333</td>\n",
       "      <td>78798.666667</td>\n",
       "      <td>79464.333333</td>\n",
       "      <td>79422.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>37754.333333</td>\n",
       "      <td>37126.000000</td>\n",
       "      <td>36747.666667</td>\n",
       "      <td>37091.333333</td>\n",
       "      <td>37895.666667</td>\n",
       "      <td>38427.333333</td>\n",
       "      <td>39466.333333</td>\n",
       "      <td>40151.000000</td>\n",
       "      <td>41106.666667</td>\n",
       "      <td>42879.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>49788.333333</td>\n",
       "      <td>50596.333333</td>\n",
       "      <td>51893.000000</td>\n",
       "      <td>53090.666667</td>\n",
       "      <td>54105.000000</td>\n",
       "      <td>54791.333333</td>\n",
       "      <td>55653.000000</td>\n",
       "      <td>56738.000000</td>\n",
       "      <td>57775.333333</td>\n",
       "      <td>58790.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>74296.666667</td>\n",
       "      <td>74184.000000</td>\n",
       "      <td>74601.000000</td>\n",
       "      <td>75399.000000</td>\n",
       "      <td>76889.666667</td>\n",
       "      <td>77711.666667</td>\n",
       "      <td>78747.333333</td>\n",
       "      <td>79980.000000</td>\n",
       "      <td>81109.333333</td>\n",
       "      <td>82264.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>101832.333333</td>\n",
       "      <td>104437.666667</td>\n",
       "      <td>105678.000000</td>\n",
       "      <td>106982.666667</td>\n",
       "      <td>108212.666667</td>\n",
       "      <td>110322.333333</td>\n",
       "      <td>112925.000000</td>\n",
       "      <td>114258.333333</td>\n",
       "      <td>115689.666667</td>\n",
       "      <td>115191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abbottstown</th>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>110443.666667</td>\n",
       "      <td>110746.666667</td>\n",
       "      <td>112320.666667</td>\n",
       "      <td>114589.666667</td>\n",
       "      <td>115723.000000</td>\n",
       "      <td>116560.000000</td>\n",
       "      <td>117499.666667</td>\n",
       "      <td>118326.333333</td>\n",
       "      <td>119869.000000</td>\n",
       "      <td>121434.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>156153.666667</td>\n",
       "      <td>156929.666667</td>\n",
       "      <td>158140.666667</td>\n",
       "      <td>158884.666667</td>\n",
       "      <td>159216.000000</td>\n",
       "      <td>159868.333333</td>\n",
       "      <td>161112.666667</td>\n",
       "      <td>163715.333333</td>\n",
       "      <td>164975.333333</td>\n",
       "      <td>166880.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abell</th>\n",
       "      <th>Maryland</th>\n",
       "      <td>192120.000000</td>\n",
       "      <td>194202.666667</td>\n",
       "      <td>197805.333333</td>\n",
       "      <td>198691.000000</td>\n",
       "      <td>204009.000000</td>\n",
       "      <td>204972.333333</td>\n",
       "      <td>207082.000000</td>\n",
       "      <td>216746.000000</td>\n",
       "      <td>223107.666667</td>\n",
       "      <td>233317.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>289837.666667</td>\n",
       "      <td>296127.333333</td>\n",
       "      <td>296486.666667</td>\n",
       "      <td>292362.333333</td>\n",
       "      <td>290749.333333</td>\n",
       "      <td>288799.333333</td>\n",
       "      <td>291532.000000</td>\n",
       "      <td>290434.333333</td>\n",
       "      <td>286827.666667</td>\n",
       "      <td>291707.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zolfo Springs</th>\n",
       "      <th>Florida</th>\n",
       "      <td>67797.000000</td>\n",
       "      <td>67545.000000</td>\n",
       "      <td>68782.666667</td>\n",
       "      <td>71349.000000</td>\n",
       "      <td>73258.666667</td>\n",
       "      <td>75546.666667</td>\n",
       "      <td>77379.666667</td>\n",
       "      <td>78499.000000</td>\n",
       "      <td>79996.000000</td>\n",
       "      <td>80942.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>97485.666667</td>\n",
       "      <td>99207.000000</td>\n",
       "      <td>100519.666667</td>\n",
       "      <td>102252.666667</td>\n",
       "      <td>105144.333333</td>\n",
       "      <td>108316.666667</td>\n",
       "      <td>110936.000000</td>\n",
       "      <td>113694.000000</td>\n",
       "      <td>116248.333333</td>\n",
       "      <td>118340.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zumbro Falls</th>\n",
       "      <th>Minnesota</th>\n",
       "      <td>176232.666667</td>\n",
       "      <td>181902.000000</td>\n",
       "      <td>179549.333333</td>\n",
       "      <td>176755.333333</td>\n",
       "      <td>180431.333333</td>\n",
       "      <td>184326.000000</td>\n",
       "      <td>188423.666667</td>\n",
       "      <td>188542.666667</td>\n",
       "      <td>194938.333333</td>\n",
       "      <td>195351.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>226557.666667</td>\n",
       "      <td>228885.333333</td>\n",
       "      <td>230470.666667</td>\n",
       "      <td>233829.333333</td>\n",
       "      <td>237131.000000</td>\n",
       "      <td>241131.666667</td>\n",
       "      <td>245362.000000</td>\n",
       "      <td>249661.666667</td>\n",
       "      <td>256043.666667</td>\n",
       "      <td>261156.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zumbrota</th>\n",
       "      <th>Minnesota</th>\n",
       "      <td>114058.666667</td>\n",
       "      <td>117036.333333</td>\n",
       "      <td>121242.333333</td>\n",
       "      <td>124992.666667</td>\n",
       "      <td>127374.333333</td>\n",
       "      <td>130058.666667</td>\n",
       "      <td>133438.333333</td>\n",
       "      <td>136748.000000</td>\n",
       "      <td>140048.000000</td>\n",
       "      <td>143269.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>160432.666667</td>\n",
       "      <td>162739.666667</td>\n",
       "      <td>165281.000000</td>\n",
       "      <td>162154.666667</td>\n",
       "      <td>157921.333333</td>\n",
       "      <td>156486.000000</td>\n",
       "      <td>155420.333333</td>\n",
       "      <td>162382.666667</td>\n",
       "      <td>172808.333333</td>\n",
       "      <td>176542.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuni</th>\n",
       "      <th>Virginia</th>\n",
       "      <td>107732.333333</td>\n",
       "      <td>109493.000000</td>\n",
       "      <td>112867.666667</td>\n",
       "      <td>115758.333333</td>\n",
       "      <td>119013.000000</td>\n",
       "      <td>121508.666667</td>\n",
       "      <td>123586.000000</td>\n",
       "      <td>125431.000000</td>\n",
       "      <td>128118.666667</td>\n",
       "      <td>132395.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>194812.666667</td>\n",
       "      <td>196558.333333</td>\n",
       "      <td>196243.666667</td>\n",
       "      <td>197259.333333</td>\n",
       "      <td>197155.333333</td>\n",
       "      <td>197569.000000</td>\n",
       "      <td>200403.333333</td>\n",
       "      <td>202839.333333</td>\n",
       "      <td>204151.000000</td>\n",
       "      <td>205919.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zwolle</th>\n",
       "      <th>Louisiana</th>\n",
       "      <td>95852.000000</td>\n",
       "      <td>97086.333333</td>\n",
       "      <td>96089.000000</td>\n",
       "      <td>97451.000000</td>\n",
       "      <td>99169.666667</td>\n",
       "      <td>101514.000000</td>\n",
       "      <td>108335.333333</td>\n",
       "      <td>111537.666667</td>\n",
       "      <td>112109.666667</td>\n",
       "      <td>116390.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>92276.333333</td>\n",
       "      <td>92854.333333</td>\n",
       "      <td>93439.000000</td>\n",
       "      <td>96243.666667</td>\n",
       "      <td>97200.666667</td>\n",
       "      <td>97760.333333</td>\n",
       "      <td>99071.333333</td>\n",
       "      <td>97303.333333</td>\n",
       "      <td>97312.333333</td>\n",
       "      <td>99356.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13309 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     2000q1         2000q2         2000q3  \\\n",
       "RegionName    State                                                         \n",
       "Abbeville     Alabama          46354.666667   47571.666667   48219.000000   \n",
       "              Georgia          37754.333333   37126.000000   36747.666667   \n",
       "              South Carolina   74296.666667   74184.000000   74601.000000   \n",
       "Abbottstown   Pennsylvania    110443.666667  110746.666667  112320.666667   \n",
       "Abell         Maryland        192120.000000  194202.666667  197805.333333   \n",
       "...                                     ...            ...            ...   \n",
       "Zolfo Springs Florida          67797.000000   67545.000000   68782.666667   \n",
       "Zumbro Falls  Minnesota       176232.666667  181902.000000  179549.333333   \n",
       "Zumbrota      Minnesota       114058.666667  117036.333333  121242.333333   \n",
       "Zuni          Virginia        107732.333333  109493.000000  112867.666667   \n",
       "Zwolle        Louisiana        95852.000000   97086.333333   96089.000000   \n",
       "\n",
       "                                     2000q4         2001q1         2001q2  \\\n",
       "RegionName    State                                                         \n",
       "Abbeville     Alabama          47987.000000   48830.000000   49521.000000   \n",
       "              Georgia          37091.333333   37895.666667   38427.333333   \n",
       "              South Carolina   75399.000000   76889.666667   77711.666667   \n",
       "Abbottstown   Pennsylvania    114589.666667  115723.000000  116560.000000   \n",
       "Abell         Maryland        198691.000000  204009.000000  204972.333333   \n",
       "...                                     ...            ...            ...   \n",
       "Zolfo Springs Florida          71349.000000   73258.666667   75546.666667   \n",
       "Zumbro Falls  Minnesota       176755.333333  180431.333333  184326.000000   \n",
       "Zumbrota      Minnesota       124992.666667  127374.333333  130058.666667   \n",
       "Zuni          Virginia        115758.333333  119013.000000  121508.666667   \n",
       "Zwolle        Louisiana        97451.000000   99169.666667  101514.000000   \n",
       "\n",
       "                                     2001q3         2001q4         2002q1  \\\n",
       "RegionName    State                                                         \n",
       "Abbeville     Alabama          49568.666667   50117.000000   50744.666667   \n",
       "              Georgia          39466.333333   40151.000000   41106.666667   \n",
       "              South Carolina   78747.333333   79980.000000   81109.333333   \n",
       "Abbottstown   Pennsylvania    117499.666667  118326.333333  119869.000000   \n",
       "Abell         Maryland        207082.000000  216746.000000  223107.666667   \n",
       "...                                     ...            ...            ...   \n",
       "Zolfo Springs Florida          77379.666667   78499.000000   79996.000000   \n",
       "Zumbro Falls  Minnesota       188423.666667  188542.666667  194938.333333   \n",
       "Zumbrota      Minnesota       133438.333333  136748.000000  140048.000000   \n",
       "Zuni          Virginia        123586.000000  125431.000000  128118.666667   \n",
       "Zwolle        Louisiana       108335.333333  111537.666667  112109.666667   \n",
       "\n",
       "                                     2002q2  ...         2014q2  \\\n",
       "RegionName    State                          ...                  \n",
       "Abbeville     Alabama          51956.333333  ...   74878.333333   \n",
       "              Georgia          42879.333333  ...   49788.333333   \n",
       "              South Carolina   82264.333333  ...  101832.333333   \n",
       "Abbottstown   Pennsylvania    121434.333333  ...  156153.666667   \n",
       "Abell         Maryland        233317.666667  ...  289837.666667   \n",
       "...                                     ...  ...            ...   \n",
       "Zolfo Springs Florida          80942.666667  ...   97485.666667   \n",
       "Zumbro Falls  Minnesota       195351.666667  ...  226557.666667   \n",
       "Zumbrota      Minnesota       143269.666667  ...  160432.666667   \n",
       "Zuni          Virginia        132395.333333  ...  194812.666667   \n",
       "Zwolle        Louisiana       116390.333333  ...   92276.333333   \n",
       "\n",
       "                                     2014q3         2014q4         2015q1  \\\n",
       "RegionName    State                                                         \n",
       "Abbeville     Alabama          75553.666667   76087.666667   76631.000000   \n",
       "              Georgia          50596.333333   51893.000000   53090.666667   \n",
       "              South Carolina  104437.666667  105678.000000  106982.666667   \n",
       "Abbottstown   Pennsylvania    156929.666667  158140.666667  158884.666667   \n",
       "Abell         Maryland        296127.333333  296486.666667  292362.333333   \n",
       "...                                     ...            ...            ...   \n",
       "Zolfo Springs Florida          99207.000000  100519.666667  102252.666667   \n",
       "Zumbro Falls  Minnesota       228885.333333  230470.666667  233829.333333   \n",
       "Zumbrota      Minnesota       162739.666667  165281.000000  162154.666667   \n",
       "Zuni          Virginia        196558.333333  196243.666667  197259.333333   \n",
       "Zwolle        Louisiana        92854.333333   93439.000000   96243.666667   \n",
       "\n",
       "                                     2015q2         2015q3         2015q4  \\\n",
       "RegionName    State                                                         \n",
       "Abbeville     Alabama          77208.000000   77741.666667   78313.333333   \n",
       "              Georgia          54105.000000   54791.333333   55653.000000   \n",
       "              South Carolina  108212.666667  110322.333333  112925.000000   \n",
       "Abbottstown   Pennsylvania    159216.000000  159868.333333  161112.666667   \n",
       "Abell         Maryland        290749.333333  288799.333333  291532.000000   \n",
       "...                                     ...            ...            ...   \n",
       "Zolfo Springs Florida         105144.333333  108316.666667  110936.000000   \n",
       "Zumbro Falls  Minnesota       237131.000000  241131.666667  245362.000000   \n",
       "Zumbrota      Minnesota       157921.333333  156486.000000  155420.333333   \n",
       "Zuni          Virginia        197155.333333  197569.000000  200403.333333   \n",
       "Zwolle        Louisiana        97200.666667   97760.333333   99071.333333   \n",
       "\n",
       "                                     2016q1         2016q2         2016q3  \n",
       "RegionName    State                                                        \n",
       "Abbeville     Alabama          78798.666667   79464.333333   79422.666667  \n",
       "              Georgia          56738.000000   57775.333333   58790.333333  \n",
       "              South Carolina  114258.333333  115689.666667  115191.000000  \n",
       "Abbottstown   Pennsylvania    163715.333333  164975.333333  166880.000000  \n",
       "Abell         Maryland        290434.333333  286827.666667  291707.333333  \n",
       "...                                     ...            ...            ...  \n",
       "Zolfo Springs Florida         113694.000000  116248.333333  118340.000000  \n",
       "Zumbro Falls  Minnesota       249661.666667  256043.666667  261156.666667  \n",
       "Zumbrota      Minnesota       162382.666667  172808.333333  176542.666667  \n",
       "Zuni          Virginia        202839.333333  204151.000000  205919.000000  \n",
       "Zwolle        Louisiana        97303.333333   97312.333333   99356.000000  \n",
       "\n",
       "[13309 rows x 67 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_housing_data_to_quarters():\n",
    "    '''Converts the housing data to quarters and returns it as mean \n",
    "    values in a dataframe. This dataframe should be a dataframe with\n",
    "    columns for 2000q1 through 2016q3, and should have a multi-index\n",
    "    in the shape of [\"State\",\"RegionName\"].\n",
    "    \n",
    "    Note: Quarters are defined in the assignment description, they are\n",
    "    not arbitrary three month periods.\n",
    "    \n",
    "    The resulting dataframe should have 67 columns, and 10,730 rows.\n",
    "    '''\n",
    "    homes = pd.read_csv(\n",
    "        'homes.csv',\n",
    "    )\n",
    "#     homes = homes.drop_duplicates(subset=['RegionName'])\n",
    "#     homes = homes.drop_duplicates(subset=['State'])\n",
    "\n",
    "    homes = homes[['RegionName','State'] + list(homes.columns[56:257])]\n",
    "    homes.drop_duplicates(['RegionName','State'], inplace=True)\n",
    "    homes.replace({\"State\": states}, inplace=True)\n",
    "#     homes = homes['State'].map(states)\n",
    "    print(type(homes))\n",
    "    homes.set_index(['RegionName','State'], inplace=True)\n",
    "    homes = homes.dropna()\n",
    "    \n",
    "#     print(cols)\n",
    "#     cols = cols[:-1]\n",
    "#     pd.rename?\n",
    "#     homes.rename(columns=cols, inplace=True)\n",
    "#     print(homes.head())\n",
    "    \n",
    "#     homes = homes.index.drop_duplicates()\n",
    "#     print(homes)\n",
    "#     a = list(range(3,51))\n",
    "#     homes.drop(homes.columns[a],axis=1,inplace=True)\n",
    "\n",
    "#     homes.set_index(['State', 'RegionName'], inplace=True)\n",
    "#     homes = homes.iloc[:,:6]\n",
    "#     homes = homes.iloc[:,:6], homes.iloc[:,7:9]]\n",
    "\n",
    "#     print(homes.iloc[:2,1:6])\n",
    "#      homes = homes['State'+'RegionName' + list(homes.columns[56:257])]\n",
    "#     homes = homes[list(homes.columns[:6]) + list(homes.columns[56:257])]\n",
    "#     print(homes.size)\n",
    "#     homes.drop_duplicates(inplace=True)\n",
    "#     print(homes.size)\n",
    "#     homes_1 = homes.iloc[:,2:]\n",
    "#     print(homes_1.head(2))\n",
    "    years = 17\n",
    "    q_per_y = 4\n",
    "    m_per_q = 3\n",
    "\n",
    "    total_group_count = years * q_per_y * m_per_q - m_per_q\n",
    "    quarter_mask = np.arange(total_group_count)//3\n",
    "#     print(quarter_mask.size, homes_1.size)\n",
    "#     print(homes_1.shape)\n",
    "#     print(homes_1.head())\n",
    "#     print(quarter_mask)\n",
    "    grouped = homes.groupby(quarter_mask, axis=1).mean()\n",
    "    grouped.sort_index(inplace=True)\n",
    "    \n",
    "    grouped.columns = [\n",
    "        str(2000+i)+'q'+str(j)\n",
    "        for i in range(17)\n",
    "        for j in range(1,5)\n",
    "    ][:-1]\n",
    "    \n",
    "#     grouped.iloc[:,:3].to_csv('tmp.csv')\n",
    "\n",
    "#     for i in range(17):\n",
    "#         for j in range(1,5):\n",
    "#             print(str(2000+i)+'q'+str(j))\n",
    "#     print(grouped.shape)\n",
    "#     for x in range(grouped.size):\n",
    "#         print(grouped.iloc[x])\n",
    "#         if x in xx:\n",
    "#             print('dup')\n",
    "#         else:\n",
    "#             xx[x] = y\n",
    "#     print(grouped.head())\n",
    "#     grouped.replace({'State':states}, inplace = True)\n",
    "#     print(grouped.iloc[13350:])\n",
    "#     print(grouped.index[13300:])\n",
    "#     transformed = grouped.transform(lambda x: x.fillna(x.mean()))\n",
    "#     print(grouped.iloc[20:30])\n",
    "#     print()\n",
    "#     print(homes['RegionName'].iloc[:20])\n",
    "#     x = homes[homes['State','RegionName']] + grouped\n",
    "#     x = get_list_of_university_towns()\n",
    "#     print(x)\n",
    "#     print(transformed.head(8))\n",
    "#     homes = homes[list(homes.columns[2:2]) + list(homes.columns[6:12])]\n",
    "#     homes = homes[:2, 3:6]\n",
    "#     print(x)\n",
    "\n",
    "    return grouped\n",
    "\n",
    "\n",
    "convert_housing_data_to_quarters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "umich_part_id": "026",
    "umich_partlist_id": "004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mani/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, 0.9051572433997666, 'non-university town')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_ttest():\n",
    "    '''First creates new data showing the decline or growth of housing prices\n",
    "    between the recession start and the recession bottom. Then runs a ttest\n",
    "    comparing the university town values to the non-university towns values, \n",
    "    return whether the alternative hypothesis (that the two groups are the same)\n",
    "    is true or not as well as the p-value of the confidence. \n",
    "    \n",
    "    Return the tuple (different, p, better) where different=True if the t-test is\n",
    "    True at a p<0.01 (we reject the null hypothesis), or different=False if \n",
    "    otherwise (we cannot reject the null hypothesis). The variable p should\n",
    "    be equal to the exact p value returned from scipy.stats.ttest_ind(). The\n",
    "    value for better should be either \"university town\" or \"non-university town\"\n",
    "    depending on which has a lower mean price ratio (which is equivilent to a\n",
    "    reduced market loss).'''\n",
    "    housing_data_quarters = convert_housing_data_to_quarters()\n",
    "    \n",
    "#     new_data = housing_data_quarters.loc[:, [before_recession, recession_bottom]].reset_index()\n",
    "#     new_data = housing_data_quarters.loc[:,recession_start:recession_bottom]\n",
    "#     new_data['Change'] = new_data['2009q2'] / new_data['2008q3']\n",
    "#     print(new_data)\n",
    "    \n",
    "    # Create university towns dummy\n",
    "    u_towns = get_list_of_university_towns()\n",
    "    u_towns = u_towns[['State', 'RegionName']]\n",
    "    u_towns['U_Town'] = 1\n",
    "    u_towns = u_towns.set_index(['State', 'RegionName'])\n",
    "    \n",
    "    # Merge university towns with housing prices by state and region name\n",
    "    x = convert_housing_data_to_quarters()\n",
    "    \n",
    "    x = x.merge(u_towns, how = 'left', left_index = True, right_index = True)\n",
    "#     print(np.where(x['U_Town'] == 1))\n",
    "    x.U_Town[x.U_Town.isnull()] = 0\n",
    "#     print(x[x['U_Town'] == 1].sum()\n",
    "#     print(x)\n",
    "    \n",
    "    start = get_recession_start()\n",
    "    bottom = get_recession_bottom()\n",
    "    y = x[[start, bottom, 'U_Town']]\n",
    "    y['Change'] = y['2009q2'] / y['2008q3']\n",
    "\n",
    "    ut = y[y['U_Town'] == 1]['Change'].dropna()\n",
    "    not_ut = y[y['U_Town'] == 0]['Change'].dropna()\n",
    "    t = ttest_ind(ut, not_ut)\n",
    "    p = t[1]\n",
    "    \n",
    "    different = False\n",
    "    if p < 0.01:\n",
    "        different = True\n",
    "\n",
    "    better = 'university town'\n",
    "    if ut.mean() < not_ut.mean():\n",
    "        better = 'non-university town'\n",
    "\n",
    "    return (different, p, better)\n",
    "\n",
    "run_ttest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-data-analysis",
   "graded_item_id": "Il9Fx",
   "launcher_item_id": "TeDW0",
   "part_id": "WGlun"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "umich": {
   "id": "Assignment 4",
   "version": "1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
